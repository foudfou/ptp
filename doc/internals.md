# Internals

## Kademlia

`net/kad/routes.c`

> In Kademlia, peers are virtually structured as leaves of a binary tree,
> which can also be vizualized as a ring. Peers are placed in the tree by
> their node ID, which is a N bits number.

Distance(A, B) = A XOR B.

The node ID `kad_guid` (`net/kad/id.h`) is a byte array of k = 20 bytes (1 in
tests, 8 in libtorrent). Kad parameters are defined in `net/kad/defs.h.in`.

> The **routing table** is implemented as hash table: an array of lists
> (buckets) of at most KAD\_K_CONST node entries [k = 8]. Instead of using a
> generic hash table implementation, we build a specialized one for specific
> operations on each list. Lists are sorted by design: depending on if we want
> to evict nodes (buckets) or get the most recent ones (replacements).

`struct list_item buckets[KAD_GUID_SPACE_IN_BITS]` (`net/kad/routes.h`).

Each **bucket** (aka *k-bucket*) points to a list of `struct kad_node`, linked
via an inner `structÂ list_item` (`utils/list.h`):

> A Linux-style circular list where the data *contains* the list.

Each bucket holds up to k active nodes (least-recently seen at the head). When
a bucket is full, a new node is placed into the **replacement cache**.

> The next time the node queries contacts in the k-bucket, any unresponsive
> ones can be evicted and replaced with entries in the replacement cache.

A **node** (`struct kad_node`) refers to a kademlia node, which we
differentiate from a **peer** (`struct peer` in `net/actions.h`):

> A "peer" is a client/server listening on a TCP port that implements some
> specific protocol (msg). A "node" is a client/server listening on a UDP port
> implementing the distributed hash table protocol (kad).

A given bucket receives nodes that are within a distance of 2^i..2^i+1 with the
current node. Which is to say that a buckets receives nodes for which the
distance with self share the same prefix.

> Ex: In a 4 bits space,for node 0 and k=3,
>   bucket 0 has nodes of distance 0..2 = node 000x, actually only 0001
>   bucket 1 has nodes of distance 2..4 = nodes 001x
>   bucket 2 has nodes of distance 4..8 = nodes 01xx
>   bucket 3 has nodes of distance 8..16 = nodes 1xxx
> Each bucket will hold up to k active nodes.

## Event loop

`server_run()` (`server.c`) creates 2 sockets, TCP and UDP, and `poll(s)`s on
them.

The loop handles events. Events are created and scheduled in 2 fashions:
*timers* (`timers.h`) or the loop's *event queue* (`evq`). I.e. on each run,
the loop: 1. applies timers, 2. dispatches events from the queue.

On I/O events generated by the `poll()`, the loop enqueues events
(`event_queue_put()`).

Timers are created via:

- `timer_init()`, which accepts a `struct timer` and can repeat;
- `set_timeout()`. which accepts an event type and creates a one-time timer
  (`.once=true`).

A timer holds an event type, ex: `event_kad_refresh`, with possible
arguments. The event type points to a callback, ex:
`event_kad_refresh_cb()`. All callbacks have the same signature, but point to
the actual callback function, ex: `kad_refresh()`. Server callback functions
are grouped as *actions* (`net/actions.c`).

## Protocols

### TCP Dummy

The TCP protocol is mostly an empty shell (2025-08). See `event_peer_data_cb` (`events.c`),
`peer_conn_handle_data()` (`net/actions.c`).

> Peers exchange messages in the Type-Length-Data (tlv) format.

### UDP Kad RPC

The server reacts to UDP datagrams:

```
event_node_data > node_handle_data() > kad_rpc_handle
```
Messages are encoded in [Bencode](https://www.bittorrent.org/beps/bep_0003.html).

> The Kademlia protocol consists of four RPCs: PING, STORE, FIND\_NODE, and
> FIND_VALUE.

#### Resource store

**This is not covered yet** (2025-08)

Kademlia operates as a distributed key-value store with two distinct
types of keys:

- Node IDs for participating nodes in the network
- Resource keys: identifiers for data/resources being stored

Both use the same key space (typically 160-bit SHA-1 hashes), but serve
different purposes.

Node lookup is handled via the routing table and covered in a later
paragraph. But resource location is based on the principle that **a resource
with key K is stored on nodes "close" to node ID = K**.

To store/find a resource with key K:

1. use `FIND_NODE(K)` to locate the nodes with IDs closest to K
2. then use `STORE` to place the value on those closest nodes, or
   `FIND_VALUE(K)` to retrieve it

## Kad lookup

FIXME
